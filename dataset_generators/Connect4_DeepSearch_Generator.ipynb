{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect 4 Deep Search Dataset Generator\n",
        "\n",
        "**Goal**: Generate 5,000+ deep MCTS games in 2-3 hours for training data.\n",
        "\n",
        "## Key Features\n",
        "- **Deeper MCTS** with heuristic rollouts (500-5,000 sims vs ULTRAFAST's 100-250)\n",
        "- **Multiprocessing** to use all available CPU cores in parallel\n",
        "- **Dual-mode**: works on Google Colab (high-RAM CPU) and local Jupyter\n",
        "- **Time-capped** with periodic checkpointing -- never lose progress\n",
        "- **6x7x2 encoding** (option b) compatible with existing training pipeline\n",
        "\n",
        "## How to Use\n",
        "1. Run all cells in order\n",
        "2. Adjust `MAX_RUNTIME_MINUTES` and `TARGET_GAMES` in the Configuration cell\n",
        "3. Dataset saves automatically as `.npz` files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Auto-Detect Environment & Setup Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# ---------- Auto-detect Colab vs Local ----------\n",
        "IS_COLAB = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "if IS_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PROJECT_DIR = '/content/drive/MyDrive/Connect4_DeepSearch'\n",
        "    print(\"Running on Google Colab\")\n",
        "else:\n",
        "    # Local Jupyter -- save next to this notebook\n",
        "    PROJECT_DIR = os.path.join(os.getcwd(), 'Connect4_DeepSearch_Output')\n",
        "    print(\"Running on Local Jupyter\")\n",
        "\n",
        "DATASET_DIR = os.path.join(PROJECT_DIR, 'datasets')\n",
        "CHECKPOINT_DIR = os.path.join(PROJECT_DIR, 'checkpoints')\n",
        "LOG_DIR = os.path.join(PROJECT_DIR, 'logs')\n",
        "\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Project directory : {PROJECT_DIR}\")\n",
        "print(f\"Dataset directory : {DATASET_DIR}\")\n",
        "print(f\"Checkpoint directory: {CHECKPOINT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Imports & Resource Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "import multiprocessing as mp\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "import gc\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # non-interactive backend (safe for Colab + local)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: tqdm for progress bars\n",
        "try:\n",
        "    from tqdm.auto import tqdm\n",
        "    HAS_TQDM = True\n",
        "except ImportError:\n",
        "    HAS_TQDM = False\n",
        "    print(\"tqdm not found -- progress bars will be text-based\")\n",
        "\n",
        "# ---------- Resource info ----------\n",
        "NUM_CPUS = os.cpu_count() or 2\n",
        "print(f\"Available CPUs: {NUM_CPUS}\")\n",
        "\n",
        "try:\n",
        "    import psutil\n",
        "    mem = psutil.virtual_memory()\n",
        "    print(f\"RAM: {mem.available / (1024**3):.1f} GB available / {mem.total / (1024**3):.1f} GB total ({mem.percent}% used)\")\n",
        "except ImportError:\n",
        "    print(\"psutil not installed -- skipping detailed memory info\")\n",
        "\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(\"Imports loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Configuration\n",
        "\n",
        "Adjust these parameters to control depth, speed, and runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== CONFIGURATION ====================\n",
        "\n",
        "# --- Target ---\n",
        "TARGET_GAMES = 6000          # Aim for 6k to guarantee >= 5k even if time-capped\n",
        "MAX_RUNTIME_MINUTES = 150    # Hard time cap (2.5 hrs, leaves buffer within 3 hrs)\n",
        "\n",
        "# --- MCTS Depth Bands ---\n",
        "# (probability, min_sims, max_sims)\n",
        "# Weighted so the average depth is ~1000 sims -- significantly deeper than ULTRAFAST's 150\n",
        "DEPTH_BANDS = [\n",
        "    (0.60,  500,  1000),   # Solid midrange depth\n",
        "    (0.25, 1000,  2000),   # Strong depth\n",
        "    (0.10, 2000,  3500),   # Very strong\n",
        "    (0.05, 3500,  5000),   # Expert-level depth\n",
        "]\n",
        "\n",
        "# --- Opening Randomness (for diversity) ---\n",
        "RANDOM_PROB = 0.15           # Probability of random move in opening phase\n",
        "RANDOM_DEPTH = 10            # Only apply random moves in first N moves of a game\n",
        "STRONG_EPSILON = 0.02        # Small chance of random MCTS move for variety\n",
        "\n",
        "# --- Multiprocessing ---\n",
        "# Use min(cpu_count, 4) to avoid overwhelming the system\n",
        "NUM_WORKERS = min(NUM_CPUS, 4)\n",
        "BATCH_PER_WORKER = 50        # Each worker generates this many games per batch\n",
        "\n",
        "# --- Checkpointing ---\n",
        "CHECKPOINT_INTERVAL_MINUTES = 20   # Save progress every N minutes\n",
        "\n",
        "# --- Reproducibility ---\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ==================== PRINT SUMMARY ====================\n",
        "avg_sims = sum(p * (lo + hi) / 2 for p, lo, hi in DEPTH_BANDS)\n",
        "print(\"=\" * 55)\n",
        "print(\"  DEEP SEARCH DATASET GENERATOR - Configuration\")\n",
        "print(\"=\" * 55)\n",
        "print(f\"  Target games       : {TARGET_GAMES:,}\")\n",
        "print(f\"  Max runtime (min)  : {MAX_RUNTIME_MINUTES}\")\n",
        "print(f\"  Avg MCTS sims/move : ~{avg_sims:.0f}\")\n",
        "print(f\"  Depth bands        : {DEPTH_BANDS}\")\n",
        "print(f\"  Random prob        : {RANDOM_PROB}\")\n",
        "print(f\"  Random depth       : {RANDOM_DEPTH}\")\n",
        "print(f\"  Strong epsilon     : {STRONG_EPSILON}\")\n",
        "print(f\"  Workers            : {NUM_WORKERS}\")\n",
        "print(f\"  Batch per worker   : {BATCH_PER_WORKER}\")\n",
        "print(f\"  Checkpoint interval: {CHECKPOINT_INTERVAL_MINUTES} min\")\n",
        "print(f\"  Seed               : {SEED}\")\n",
        "print(\"=\" * 55)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Fast Connect4 Engine\n",
        "\n",
        "Optimized engine with `heights` array to avoid recomputing column fill levels on every move."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Connect4:\n",
        "    \"\"\"Fast Connect 4 engine with height-tracking for O(1) move placement.\"\"\"\n",
        "\n",
        "    __slots__ = ['board', 'heights', 'current_player', 'winner', 'move_count']\n",
        "\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((6, 7), dtype=np.int8)\n",
        "        self.heights = np.zeros(7, dtype=np.int8)   # tracks how many pieces in each column\n",
        "        self.current_player = 1\n",
        "        self.winner = None\n",
        "        self.move_count = 0\n",
        "\n",
        "    def copy(self):\n",
        "        g = Connect4()\n",
        "        g.board = self.board.copy()\n",
        "        g.heights = self.heights.copy()\n",
        "        g.current_player = self.current_player\n",
        "        g.winner = self.winner\n",
        "        g.move_count = self.move_count\n",
        "        return g\n",
        "\n",
        "    def legal_moves(self):\n",
        "        \"\"\"Return list of columns that are not full.\"\"\"\n",
        "        return [c for c in range(7) if self.heights[c] < 6]\n",
        "\n",
        "    def make_move(self, col):\n",
        "        \"\"\"Place piece in column. Returns False if illegal.\"\"\"\n",
        "        if col < 0 or col > 6 or self.heights[col] >= 6:\n",
        "            return False\n",
        "        row = int(self.heights[col])\n",
        "        self.board[row, col] = self.current_player\n",
        "        self.heights[col] += 1\n",
        "        self.move_count += 1\n",
        "\n",
        "        if self._check_win(row, col):\n",
        "            self.winner = self.current_player\n",
        "        elif self.move_count >= 42:\n",
        "            self.winner = 0  # draw\n",
        "\n",
        "        self.current_player *= -1\n",
        "        return True\n",
        "\n",
        "    def _check_win(self, row, col):\n",
        "        \"\"\"Check if last move at (row, col) created a 4-in-a-row.\"\"\"\n",
        "        player = self.board[row, col]\n",
        "\n",
        "        # Vertical (only need to check downward since piece sits on top)\n",
        "        if row >= 3:\n",
        "            if (self.board[row, col] + self.board[row-1, col] +\n",
        "                self.board[row-2, col] + self.board[row-3, col]) == 4 * player:\n",
        "                return True\n",
        "\n",
        "        # Horizontal\n",
        "        for start in range(max(0, col - 3), min(4, col + 1)):\n",
        "            if np.sum(self.board[row, start:start+4]) == 4 * player:\n",
        "                return True\n",
        "\n",
        "        # Diagonals (extend in both directions)\n",
        "        for dr, dc in [(1, 1), (1, -1)]:\n",
        "            count = 1\n",
        "            for sign in [1, -1]:\n",
        "                r, c = row + sign * dr, col + sign * dc\n",
        "                while 0 <= r < 6 and 0 <= c < 7 and self.board[r, c] == player:\n",
        "                    count += 1\n",
        "                    r += sign * dr\n",
        "                    c += sign * dc\n",
        "            if count >= 4:\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return self.winner is not None\n",
        "\n",
        "    def get_result(self, player):\n",
        "        \"\"\"Return +1 if player won, -1 if lost, 0 if draw or not finished.\"\"\"\n",
        "        if self.winner is None:\n",
        "            return 0.0\n",
        "        if self.winner == 0:\n",
        "            return 0.0\n",
        "        return 1.0 if self.winner == player else -1.0\n",
        "\n",
        "    def encode(self):\n",
        "        \"\"\"6x7x2 encoding (option b from project description).\"\"\"\n",
        "        enc = np.zeros((6, 7, 2), dtype=np.float32)\n",
        "        enc[:, :, 0] = (self.board == 1).astype(np.float32)\n",
        "        enc[:, :, 1] = (self.board == -1).astype(np.float32)\n",
        "        return enc\n",
        "\n",
        "    def board_hash(self):\n",
        "        \"\"\"Fast hash for transposition lookups.\"\"\"\n",
        "        return hash(self.board.tobytes())\n",
        "\n",
        "print(\"Connect4 engine loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: MCTS with Heuristic Rollouts\n",
        "\n",
        "the agent checks for immediate wins and blocks before falling back to random moves. This gives much higher quality evaluations per simulation.\n",
        "I think it reduces by effectively making 500 heuristic sims comparable to 1,500+ random sims."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DeepMCTS:\n",
        "    \"\"\"MCTS with heuristic rollouts, win/block shortcuts, and UCB1 selection.\"\"\"\n",
        "\n",
        "    def __init__(self, default_sims=800):\n",
        "        self.default_sims = default_sims\n",
        "\n",
        "    # ---------- Public API ----------\n",
        "\n",
        "    def get_move(self, game, sims=None):\n",
        "        \"\"\"Return the best column to play.\"\"\"\n",
        "        sims = sims or self.default_sims\n",
        "        player = game.current_player\n",
        "\n",
        "        # Instant win check\n",
        "        win_col = self._find_winning_move(game, player)\n",
        "        if win_col is not None:\n",
        "            return win_col\n",
        "\n",
        "        # Instant block check\n",
        "        block_col = self._find_winning_move(game, -player)\n",
        "        if block_col is not None:\n",
        "            return block_col\n",
        "\n",
        "        # Full MCTS search\n",
        "        return self._search(game, sims)\n",
        "\n",
        "    # ---------- MCTS core ----------\n",
        "\n",
        "    def _search(self, game, sims):\n",
        "        root_player = game.current_player\n",
        "        # stats: board_hash -> [visits, value_sum]\n",
        "        stats = {}\n",
        "\n",
        "        for _ in range(sims):\n",
        "            node = game.copy()\n",
        "            path = []\n",
        "\n",
        "            # --- Selection + Expansion ---\n",
        "            while not node.is_terminal():\n",
        "                state = node.board_hash()\n",
        "                path.append(state)\n",
        "\n",
        "                if state not in stats:\n",
        "                    stats[state] = [0, 0.0]\n",
        "\n",
        "                moves = node.legal_moves()\n",
        "                if not moves:\n",
        "                    break\n",
        "\n",
        "                # UCB1 selection\n",
        "                best_move = None\n",
        "                best_ucb = -1e18\n",
        "                parent_visits = stats[state][0]\n",
        "\n",
        "                for col in moves:\n",
        "                    test = node.copy()\n",
        "                    test.make_move(col)\n",
        "                    child_hash = test.board_hash()\n",
        "\n",
        "                    if child_hash not in stats:\n",
        "                        stats[child_hash] = [0, 0.0]\n",
        "\n",
        "                    visits, value = stats[child_hash]\n",
        "\n",
        "                    if visits == 0:\n",
        "                        ucb = 1e18  # explore unvisited first\n",
        "                    else:\n",
        "                        exploit = value / visits\n",
        "                        explore = 1.414 * np.sqrt(np.log(parent_visits + 1) / visits)\n",
        "                        ucb = exploit + explore\n",
        "\n",
        "                    if ucb > best_ucb:\n",
        "                        best_ucb = ucb\n",
        "                        best_move = col\n",
        "\n",
        "                node.make_move(best_move)\n",
        "\n",
        "                # If this is a new node, expand and rollout\n",
        "                child_state = node.board_hash()\n",
        "                if child_state not in stats or stats[child_state][0] == 0:\n",
        "                    if child_state not in stats:\n",
        "                        stats[child_state] = [0, 0.0]\n",
        "                    path.append(child_state)\n",
        "                    break\n",
        "\n",
        "            # --- Heuristic Rollout ---\n",
        "            result = self._heuristic_rollout(node, root_player)\n",
        "\n",
        "            # --- Backpropagation ---\n",
        "            for state in path:\n",
        "                if state in stats:\n",
        "                    stats[state][0] += 1\n",
        "                    stats[state][1] += result\n",
        "\n",
        "        # --- Choose best move by visit count ---\n",
        "        best_move = None\n",
        "        best_visits = -1\n",
        "\n",
        "        for col in game.legal_moves():\n",
        "            test = game.copy()\n",
        "            test.make_move(col)\n",
        "            st = test.board_hash()\n",
        "\n",
        "            visits = stats[st][0] if st in stats else 0\n",
        "            if visits > best_visits:\n",
        "                best_visits = visits\n",
        "                best_move = col\n",
        "\n",
        "        return best_move if best_move is not None else random.choice(game.legal_moves())\n",
        "\n",
        "    # ---------- Heuristic rollout ----------\n",
        "\n",
        "    def _heuristic_rollout(self, game, root_player, max_depth=30):\n",
        "        \"\"\"\n",
        "        Rollout with heuristic move ordering:\n",
        "        1. Play winning move if available\n",
        "        2. Block opponent's winning move\n",
        "        3. Prefer center columns\n",
        "        4. Random fallback\n",
        "        \"\"\"\n",
        "        node = game.copy()\n",
        "        depth = 0\n",
        "\n",
        "        while not node.is_terminal() and depth < max_depth:\n",
        "            moves = node.legal_moves()\n",
        "            if not moves:\n",
        "                break\n",
        "\n",
        "            player = node.current_player\n",
        "\n",
        "            # 1) Check for immediate win\n",
        "            win_col = self._find_winning_move(node, player)\n",
        "            if win_col is not None:\n",
        "                node.make_move(win_col)\n",
        "                depth += 1\n",
        "                continue\n",
        "\n",
        "            # 2) Check for immediate block\n",
        "            block_col = self._find_winning_move(node, -player)\n",
        "            if block_col is not None:\n",
        "                node.make_move(block_col)\n",
        "                depth += 1\n",
        "                continue\n",
        "\n",
        "            # 3) Center-biased random (center columns are strategically better)\n",
        "            #    Column order: 3, 2, 4, 1, 5, 0, 6\n",
        "            center_order = [3, 2, 4, 1, 5, 0, 6]\n",
        "            available_center = [c for c in center_order if c in moves]\n",
        "\n",
        "            if random.random() < 0.6 and available_center:\n",
        "                # 60% of the time, bias toward center\n",
        "                col = available_center[0]\n",
        "            else:\n",
        "                col = random.choice(moves)\n",
        "\n",
        "            node.make_move(col)\n",
        "            depth += 1\n",
        "\n",
        "        return node.get_result(root_player)\n",
        "\n",
        "    # ---------- Utility ----------\n",
        "\n",
        "    def _find_winning_move(self, game, player):\n",
        "        \"\"\"Check if `player` can win in one move. Returns column or None.\"\"\"\n",
        "        for col in game.legal_moves():\n",
        "            test = game.copy()\n",
        "            # Temporarily set the player so make_move uses the right piece\n",
        "            saved_player = test.current_player\n",
        "            test.current_player = player\n",
        "            test.make_move(col)\n",
        "            if test.winner == player:\n",
        "                return col\n",
        "            # Restore (not strictly needed since we discard `test`)\n",
        "        return None\n",
        "\n",
        "\n",
        "# ---------- Depth sampler ----------\n",
        "\n",
        "def sample_depth():\n",
        "    \"\"\"Sample MCTS simulation count from the configured depth bands.\"\"\"\n",
        "    r = random.random()\n",
        "    acc = 0.0\n",
        "    for pct, lo, hi in DEPTH_BANDS:\n",
        "        acc += pct\n",
        "        if r <= acc:\n",
        "            return random.randint(lo, hi)\n",
        "    # Fallback to last band\n",
        "    return random.randint(DEPTH_BANDS[-1][1], DEPTH_BANDS[-1][2])\n",
        "\n",
        "print(\"DeepMCTS engine loaded\")\n",
        "print(f\"Avg sims per move: ~{sum(p * (lo+hi)/2 for p, lo, hi in DEPTH_BANDS):.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Single Game Generator\n",
        "\n",
        "Plays one full game of Connect 4 using Deep MCTS. Random opening moves create diversity\n",
        "but are NOT recorded in the dataset (per project spec -- only MCTS-recommended moves are stored)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_one_game(seed_offset=0):\n",
        "    \"\"\"\n",
        "    Play a single game and return (boards_list, moves_list, metadata_dict).\n",
        "\n",
        "    - Random opening moves are played but NOT recorded.\n",
        "    - MCTS-recommended moves ARE recorded with the board encoded from\n",
        "      player 1's perspective (flipping for player -1).\n",
        "    - Each worker gets a unique seed_offset for reproducibility.\n",
        "    \"\"\"\n",
        "    # Per-call seed so each multiprocessing worker is independent\n",
        "    local_rng = random.Random(SEED + seed_offset + int(time.time() * 1000) % 100000)\n",
        "    np_rng = np.random.RandomState(SEED + seed_offset + int(time.time() * 1000) % 100000)\n",
        "\n",
        "    mcts_player = DeepMCTS()\n",
        "    game = Connect4()\n",
        "\n",
        "    game_boards = []\n",
        "    game_moves = []\n",
        "    depths_used = []\n",
        "    move_num = 0\n",
        "\n",
        "    while not game.is_terminal():\n",
        "        current_player = game.current_player\n",
        "\n",
        "        # Random opening phase -- diverse starts, not recorded\n",
        "        use_random = (move_num < RANDOM_DEPTH and local_rng.random() < RANDOM_PROB)\n",
        "\n",
        "        if use_random:\n",
        "            col = local_rng.choice(game.legal_moves())\n",
        "        else:\n",
        "            # Sample depth from bands\n",
        "            depth = sample_depth()\n",
        "            depths_used.append(depth)\n",
        "\n",
        "            # Small epsilon for variety\n",
        "            if local_rng.random() < STRONG_EPSILON:\n",
        "                col = local_rng.choice(game.legal_moves())\n",
        "            else:\n",
        "                col = mcts_player.get_move(game, sims=depth)\n",
        "\n",
        "            # Encode board from player 1 perspective\n",
        "            if current_player == 1:\n",
        "                board_enc = game.encode()\n",
        "            else:\n",
        "                flipped = game.copy()\n",
        "                flipped.board = -flipped.board\n",
        "                board_enc = flipped.encode()\n",
        "\n",
        "            game_boards.append(board_enc)\n",
        "            game_moves.append(col)\n",
        "\n",
        "        game.make_move(col)\n",
        "        move_num += 1\n",
        "\n",
        "        if move_num > 42:\n",
        "            break\n",
        "\n",
        "    # Game metadata\n",
        "    avg_depth = sum(depths_used) / len(depths_used) if depths_used else 0\n",
        "    result = 'p1_win' if game.winner == 1 else ('p2_win' if game.winner == -1 else 'draw')\n",
        "\n",
        "    meta = {\n",
        "        'avg_depth': avg_depth,\n",
        "        'max_depth': max(depths_used) if depths_used else 0,\n",
        "        'total_moves': move_num,\n",
        "        'recorded_positions': len(game_boards),\n",
        "        'result': result,\n",
        "    }\n",
        "\n",
        "    return game_boards, game_moves, meta\n",
        "\n",
        "\n",
        "def generate_batch(args):\n",
        "    \"\"\"\n",
        "    Worker function for multiprocessing.\n",
        "    Generates `num_games` games and returns aggregated results.\n",
        "    \"\"\"\n",
        "    batch_id, num_games, start_time_global, max_runtime_sec = args\n",
        "\n",
        "    batch_boards = []\n",
        "    batch_moves = []\n",
        "    batch_metas = []\n",
        "    games_done = 0\n",
        "\n",
        "    for i in range(num_games):\n",
        "        # Check time cap\n",
        "        if time.time() - start_time_global >= max_runtime_sec:\n",
        "            break\n",
        "\n",
        "        boards, moves, meta = generate_one_game(seed_offset=batch_id * 10000 + i)\n",
        "        batch_boards.extend(boards)\n",
        "        batch_moves.extend(moves)\n",
        "        batch_metas.append(meta)\n",
        "        games_done += 1\n",
        "\n",
        "    return batch_boards, batch_moves, batch_metas, games_done\n",
        "\n",
        "print(\"Game generator loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Parallel Dataset Generator\n",
        "\n",
        "Uses multiprocessing to generate games on all available CPU cores simultaneously.\n",
        "Includes periodic checkpointing (every 20 min) and a hard time cap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _try_multiprocessing():\n",
        "    \"\"\"\n",
        "    Test whether multiprocessing works in this environment.\n",
        "    Jupyter notebooks + 'spawn' context often can't pickle notebook-defined functions.\n",
        "    Linux (Colab) with 'fork' usually works. macOS defaults to 'spawn' which doesn't.\n",
        "    Returns True if MP is usable, False otherwise.\n",
        "    \"\"\"\n",
        "    if NUM_WORKERS <= 1:\n",
        "        return False\n",
        "    try:\n",
        "        ctx = mp.get_context('fork')\n",
        "        with ctx.Pool(1) as pool:\n",
        "            result = pool.map(generate_batch, [(0, 1, time.time(), 600)])\n",
        "        return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Try spawn as fallback (usually fails in notebooks but worth trying)\n",
        "    try:\n",
        "        ctx = mp.get_context('spawn')\n",
        "        with ctx.Pool(1) as pool:\n",
        "            result = pool.map(generate_batch, [(0, 1, time.time(), 600)])\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def _run_parallel_batch(batch_id, games_per_worker, start_time, max_runtime_sec, n_workers):\n",
        "    \"\"\"Run a batch of games in parallel using multiprocessing fork context.\"\"\"\n",
        "    worker_args = [\n",
        "        (batch_id * n_workers + w, games_per_worker, start_time, max_runtime_sec)\n",
        "        for w in range(n_workers)\n",
        "    ]\n",
        "    ctx = mp.get_context('fork')\n",
        "    with ctx.Pool(processes=n_workers) as pool:\n",
        "        results = pool.map(generate_batch, worker_args)\n",
        "    return results\n",
        "\n",
        "\n",
        "def generate_deep_dataset():\n",
        "    \"\"\"\n",
        "    Main generation loop.\n",
        "    - Attempts multiprocessing (fork context); falls back to sequential if unavailable\n",
        "    - Collects results and checkpoints periodically\n",
        "    - Stops when TARGET_GAMES reached or time cap hit\n",
        "    \"\"\"\n",
        "    all_boards = []\n",
        "    all_moves = []\n",
        "    all_metas = []\n",
        "    total_games = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "    max_runtime_sec = MAX_RUNTIME_MINUTES * 60\n",
        "    last_checkpoint_time = start_time\n",
        "    checkpoint_num = 0\n",
        "\n",
        "    log_lines = []\n",
        "\n",
        "    def log(msg):\n",
        "        ts = datetime.now().strftime('%H:%M:%S')\n",
        "        line = f\"[{ts}] {msg}\"\n",
        "        print(line)\n",
        "        log_lines.append(line)\n",
        "\n",
        "    log(f\"Starting deep dataset generation\")\n",
        "    log(f\"Target: {TARGET_GAMES:,} games | Time cap: {MAX_RUNTIME_MINUTES} min | Workers: {NUM_WORKERS}\")\n",
        "    log(f\"Avg MCTS depth: ~{sum(p*(lo+hi)/2 for p,lo,hi in DEPTH_BANDS):.0f} sims/move\")\n",
        "\n",
        "    # Test multiprocessing availability\n",
        "    use_mp = _try_multiprocessing()\n",
        "    if use_mp:\n",
        "        log(f\"Multiprocessing available -- using {NUM_WORKERS} workers (fork context)\")\n",
        "    else:\n",
        "        log(\"Multiprocessing not available in this environment -- using single-process mode\")\n",
        "        log(\"(This is normal for macOS Jupyter. On Colab Linux, fork context should work.)\")\n",
        "\n",
        "    batch_id = 0\n",
        "\n",
        "    while total_games < TARGET_GAMES:\n",
        "        elapsed_sec = time.time() - start_time\n",
        "        if elapsed_sec >= max_runtime_sec:\n",
        "            log(\"Time cap reached. Stopping generation.\")\n",
        "            break\n",
        "\n",
        "        remaining = TARGET_GAMES - total_games\n",
        "        remaining_time_sec = max_runtime_sec - elapsed_sec\n",
        "        if remaining_time_sec <= 0:\n",
        "            break\n",
        "\n",
        "        if use_mp:\n",
        "            games_per_worker = min(BATCH_PER_WORKER, max(1, remaining // NUM_WORKERS))\n",
        "            try:\n",
        "                results = _run_parallel_batch(\n",
        "                    batch_id, games_per_worker, start_time, max_runtime_sec, NUM_WORKERS\n",
        "                )\n",
        "                for boards, moves, metas, games_done in results:\n",
        "                    all_boards.extend(boards)\n",
        "                    all_moves.extend(moves)\n",
        "                    all_metas.extend(metas)\n",
        "                    total_games += games_done\n",
        "            except Exception as e:\n",
        "                log(f\"Multiprocessing error: {e}. Falling back to sequential.\")\n",
        "                use_mp = False\n",
        "                continue\n",
        "        else:\n",
        "            # Sequential fallback\n",
        "            games_this_batch = min(BATCH_PER_WORKER, remaining)\n",
        "            boards, moves, metas, games_done = generate_batch(\n",
        "                (batch_id, games_this_batch, start_time, max_runtime_sec)\n",
        "            )\n",
        "            all_boards.extend(boards)\n",
        "            all_moves.extend(moves)\n",
        "            all_metas.extend(metas)\n",
        "            total_games += games_done\n",
        "\n",
        "        batch_id += 1\n",
        "\n",
        "        # Progress report\n",
        "        elapsed_min = (time.time() - start_time) / 60.0\n",
        "        rate = total_games / max(elapsed_min, 0.01)\n",
        "        eta_min = (TARGET_GAMES - total_games) / max(rate, 0.01)\n",
        "        log(f\"Games: {total_games:,}/{TARGET_GAMES:,} | \"\n",
        "            f\"Examples: {len(all_boards):,} | \"\n",
        "            f\"Rate: {rate:.1f} games/min | \"\n",
        "            f\"Elapsed: {elapsed_min:.1f} min | \"\n",
        "            f\"ETA: {eta_min:.1f} min\")\n",
        "\n",
        "        # Periodic checkpoint\n",
        "        if (time.time() - last_checkpoint_time) / 60.0 >= CHECKPOINT_INTERVAL_MINUTES:\n",
        "            checkpoint_num += 1\n",
        "            ckpt_path = os.path.join(CHECKPOINT_DIR, f'deep_ckpt_{checkpoint_num:03d}.pkl')\n",
        "            with open(ckpt_path, 'wb') as f:\n",
        "                pickle.dump({\n",
        "                    'boards': all_boards,\n",
        "                    'moves': all_moves,\n",
        "                    'games': total_games,\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                }, f)\n",
        "            log(f\"Checkpoint {checkpoint_num} saved -> {ckpt_path}\")\n",
        "            last_checkpoint_time = time.time()\n",
        "            gc.collect()\n",
        "\n",
        "    # Final checkpoint\n",
        "    checkpoint_num += 1\n",
        "    ckpt_path = os.path.join(CHECKPOINT_DIR, f'deep_ckpt_{checkpoint_num:03d}.pkl')\n",
        "    with open(ckpt_path, 'wb') as f:\n",
        "        pickle.dump({\n",
        "            'boards': all_boards,\n",
        "            'moves': all_moves,\n",
        "            'games': total_games,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "        }, f)\n",
        "    log(f\"Final checkpoint {checkpoint_num} saved -> {ckpt_path}\")\n",
        "\n",
        "    # Compute summary stats\n",
        "    elapsed_total = (time.time() - start_time) / 60.0\n",
        "    p1_wins = sum(1 for m in all_metas if m['result'] == 'p1_win')\n",
        "    p2_wins = sum(1 for m in all_metas if m['result'] == 'p2_win')\n",
        "    draws = sum(1 for m in all_metas if m['result'] == 'draw')\n",
        "    avg_depth = np.mean([m['avg_depth'] for m in all_metas]) if all_metas else 0\n",
        "    avg_positions = np.mean([m['recorded_positions'] for m in all_metas]) if all_metas else 0\n",
        "\n",
        "    log(\"=\" * 55)\n",
        "    log(\"GENERATION COMPLETE\")\n",
        "    log(\"=\" * 55)\n",
        "    log(f\"Total games     : {total_games:,}\")\n",
        "    log(f\"Total examples  : {len(all_boards):,}\")\n",
        "    log(f\"Total time      : {elapsed_total:.1f} min ({elapsed_total/60:.2f} hrs)\")\n",
        "    log(f\"Rate            : {total_games/max(elapsed_total,0.01):.1f} games/min\")\n",
        "    log(f\"Avg MCTS depth  : {avg_depth:.0f} sims/move\")\n",
        "    log(f\"Avg positions   : {avg_positions:.1f} per game\")\n",
        "    log(f\"P1 wins: {p1_wins} ({100*p1_wins/max(total_games,1):.1f}%) | \"\n",
        "        f\"P2 wins: {p2_wins} ({100*p2_wins/max(total_games,1):.1f}%) | \"\n",
        "        f\"Draws: {draws} ({100*draws/max(total_games,1):.1f}%)\")\n",
        "\n",
        "    # Save log\n",
        "    log_path = os.path.join(LOG_DIR, f'generation_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
        "    with open(log_path, 'w') as f:\n",
        "        f.write('\\n'.join(log_lines))\n",
        "    print(f\"Log saved -> {log_path}\")\n",
        "\n",
        "    return np.array(all_boards), np.array(all_moves), all_metas\n",
        "\n",
        "print(\"Dataset generator ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: RUN GENERATION (Main Cell)\n",
        "\n",
        "This is the main execution cell. It will run for up to `MAX_RUNTIME_MINUTES` and\n",
        "generate as many deep games as possible. Progress is printed periodically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 55)\n",
        "print(\"  STARTING DEEP DATASET GENERATION\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "X_raw, y_raw, game_metas = generate_deep_dataset()\n",
        "\n",
        "print(f\"\\nRaw dataset:\")\n",
        "print(f\"  X shape: {X_raw.shape}\")\n",
        "print(f\"  y shape: {y_raw.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9: Data Augmentation (Horizontal Flip)\n",
        "\n",
        "Doubles the dataset by mirroring every board and its corresponding move."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_dataset(boards, moves):\n",
        "    \"\"\"Horizontal flip augmentation -- doubles the dataset.\"\"\"\n",
        "    n = len(boards)\n",
        "    aug_boards = np.zeros((n * 2, 6, 7, 2), dtype=np.float32)\n",
        "    aug_moves = np.zeros(n * 2, dtype=np.int64)\n",
        "\n",
        "    print(f\"Augmenting {n:,} examples with horizontal flips...\")\n",
        "\n",
        "    for i in range(n):\n",
        "        # Original\n",
        "        aug_boards[2 * i] = boards[i]\n",
        "        aug_moves[2 * i] = moves[i]\n",
        "\n",
        "        # Horizontally flipped\n",
        "        aug_boards[2 * i + 1] = np.flip(boards[i], axis=1)\n",
        "        aug_moves[2 * i + 1] = 6 - moves[i]\n",
        "\n",
        "    return aug_boards, aug_moves\n",
        "\n",
        "\n",
        "X_aug, y_aug = augment_dataset(X_raw, y_raw)\n",
        "\n",
        "print(f\"\\nAugmentation complete!\")\n",
        "print(f\"  Original : {len(X_raw):,} examples\")\n",
        "print(f\"  Augmented: {len(X_aug):,} examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10: Quality Analysis & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Statistics ----------\n",
        "print(\"=\" * 55)\n",
        "print(\"  DATASET QUALITY REPORT\")\n",
        "print(\"=\" * 55)\n",
        "print(f\"Total examples (augmented): {len(X_aug):,}\")\n",
        "print(f\"X shape: {X_aug.shape}\")\n",
        "print(f\"y shape: {y_aug.shape}\")\n",
        "\n",
        "print(f\"\\nMove distribution:\")\n",
        "for col in range(7):\n",
        "    count = np.sum(y_aug == col)\n",
        "    pct = 100 * count / len(y_aug)\n",
        "    bar = '#' * int(pct)\n",
        "    print(f\"  Column {col}: {count:>7,} ({pct:5.1f}%) {bar}\")\n",
        "\n",
        "# Game outcome stats\n",
        "if game_metas:\n",
        "    p1w = sum(1 for m in game_metas if m['result'] == 'p1_win')\n",
        "    p2w = sum(1 for m in game_metas if m['result'] == 'p2_win')\n",
        "    drw = sum(1 for m in game_metas if m['result'] == 'draw')\n",
        "    total = len(game_metas)\n",
        "    print(f\"\\nGame outcomes ({total:,} games):\")\n",
        "    print(f\"  P1 wins: {p1w:,} ({100*p1w/total:.1f}%)\")\n",
        "    print(f\"  P2 wins: {p2w:,} ({100*p2w/total:.1f}%)\")\n",
        "    print(f\"  Draws  : {drw:,} ({100*drw/total:.1f}%)\")\n",
        "\n",
        "    depths = [m['avg_depth'] for m in game_metas]\n",
        "    print(f\"\\nMCTS depth stats:\")\n",
        "    print(f\"  Mean : {np.mean(depths):.0f} sims\")\n",
        "    print(f\"  Min  : {np.min(depths):.0f} sims\")\n",
        "    print(f\"  Max  : {np.max(depths):.0f} sims\")\n",
        "    print(f\"  Median: {np.median(depths):.0f} sims\")\n",
        "\n",
        "# ---------- Visualizations ----------\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1) Move distribution\n",
        "move_counts = np.bincount(y_aug.astype(int), minlength=7)\n",
        "axes[0, 0].bar(range(7), move_counts, color='steelblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Move Distribution (Augmented)', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Column')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "\n",
        "# 2) Game stage coverage (pieces on board)\n",
        "piece_counts = [np.sum(board) for board in X_aug[:min(len(X_aug), 50000)]]\n",
        "axes[0, 1].hist(piece_counts, bins=30, color='green', edgecolor='black', alpha=0.8)\n",
        "axes[0, 1].set_title('Game Stage Coverage', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Total Pieces on Board')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "# 3) MCTS depth distribution\n",
        "if game_metas:\n",
        "    axes[1, 0].hist(depths, bins=40, color='purple', edgecolor='black', alpha=0.8)\n",
        "    axes[1, 0].set_title('MCTS Depth Distribution', fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Avg Sims per Game')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].axvline(np.mean(depths), color='red', linestyle='--', label=f'Mean: {np.mean(depths):.0f}')\n",
        "    axes[1, 0].legend()\n",
        "\n",
        "# 4) Sample board visualization\n",
        "idx = random.randint(0, len(X_aug) - 1)\n",
        "sample_board = X_aug[idx]\n",
        "board_2d = sample_board[:, :, 0] - sample_board[:, :, 1]\n",
        "im = axes[1, 1].imshow(board_2d, cmap='RdBu', vmin=-1, vmax=1)\n",
        "axes[1, 1].set_title(f'Sample Board (Move: Col {y_aug[idx]})', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Column')\n",
        "axes[1, 1].set_ylabel('Row')\n",
        "plt.colorbar(im, ax=axes[1, 1], shrink=0.8)\n",
        "\n",
        "plt.tight_layout()\n",
        "analysis_path = os.path.join(PROJECT_DIR, 'deep_dataset_analysis.png')\n",
        "plt.savefig(analysis_path, dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"\\nAnalysis plot saved -> {analysis_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 11: Save Final Dataset\n",
        "\n",
        "Saves both the raw and augmented datasets as compressed `.npz` files,\n",
        "plus metadata as JSON. Compatible with existing training notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Save compressed numpy ---\n",
        "npz_path = os.path.join(DATASET_DIR, 'connect4_deep_search.npz')\n",
        "np.savez_compressed(\n",
        "    npz_path,\n",
        "    X_train=X_aug,\n",
        "    y_train=y_aug,\n",
        ")\n",
        "print(f\"Augmented dataset saved -> {npz_path}\")\n",
        "\n",
        "# Also save original (pre-augmentation) for reference\n",
        "npz_raw_path = os.path.join(DATASET_DIR, 'connect4_deep_search_raw.npz')\n",
        "np.savez_compressed(\n",
        "    npz_raw_path,\n",
        "    X_train=X_raw,\n",
        "    y_train=y_raw,\n",
        ")\n",
        "print(f\"Raw dataset saved      -> {npz_raw_path}\")\n",
        "\n",
        "# --- Metadata ---\n",
        "metadata = {\n",
        "    'total_games': len(game_metas),\n",
        "    'total_examples_raw': len(X_raw),\n",
        "    'total_examples_augmented': len(X_aug),\n",
        "    'encoding': '6x7x2 (option b)',\n",
        "    'augmentation': 'horizontal_flip',\n",
        "    'depth_bands': DEPTH_BANDS,\n",
        "    'avg_mcts_depth': float(np.mean([m['avg_depth'] for m in game_metas])) if game_metas else 0,\n",
        "    'random_prob': RANDOM_PROB,\n",
        "    'random_depth': RANDOM_DEPTH,\n",
        "    'strong_epsilon': STRONG_EPSILON,\n",
        "    'max_runtime_minutes': MAX_RUNTIME_MINUTES,\n",
        "    'num_workers': NUM_WORKERS,\n",
        "    'seed': SEED,\n",
        "    'generation_date': datetime.now().isoformat(),\n",
        "    'game_results': {\n",
        "        'p1_wins': sum(1 for m in game_metas if m['result'] == 'p1_win'),\n",
        "        'p2_wins': sum(1 for m in game_metas if m['result'] == 'p2_win'),\n",
        "        'draws': sum(1 for m in game_metas if m['result'] == 'draw'),\n",
        "    },\n",
        "}\n",
        "\n",
        "meta_path = os.path.join(DATASET_DIR, 'deep_search_metadata.json')\n",
        "with open(meta_path, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "print(f\"Metadata saved         -> {meta_path}\")\n",
        "\n",
        "# --- File sizes ---\n",
        "print(f\"\\nFile sizes:\")\n",
        "for fname in ['connect4_deep_search.npz', 'connect4_deep_search_raw.npz', 'deep_search_metadata.json']:\n",
        "    fpath = os.path.join(DATASET_DIR, fname)\n",
        "    if os.path.exists(fpath):\n",
        "        size_mb = os.path.getsize(fpath) / (1024**2)\n",
        "        print(f\"  {fname}: {size_mb:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 12: Merge with Existing Dataset (Optional)\n",
        "\n",
        "If you have a previously generated dataset (e.g. from the ULTRAFAST or Production notebooks),\n",
        "you can merge it with the deep search dataset here. Update `EXISTING_DATASET_PATH` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== OPTIONAL: Merge with existing dataset ==========\n",
        "# Set this to the path of your existing .npz file, or None to skip\n",
        "\n",
        "EXISTING_DATASET_PATH = None  # e.g. '/content/drive/MyDrive/Connect4_FAST/datasets/connect4_fast.npz'\n",
        "\n",
        "if EXISTING_DATASET_PATH and os.path.exists(EXISTING_DATASET_PATH):\n",
        "    print(f\"Loading existing dataset from: {EXISTING_DATASET_PATH}\")\n",
        "    existing = np.load(EXISTING_DATASET_PATH)\n",
        "\n",
        "    X_existing = existing['X_train']\n",
        "    y_existing = existing['y_train']\n",
        "    print(f\"  Existing: X={X_existing.shape}, y={y_existing.shape}\")\n",
        "\n",
        "    # Concatenate\n",
        "    X_merged = np.concatenate([X_existing, X_aug], axis=0)\n",
        "    y_merged = np.concatenate([y_existing, y_aug], axis=0)\n",
        "\n",
        "    # Shuffle\n",
        "    indices = np.random.permutation(len(X_merged))\n",
        "    X_merged = X_merged[indices]\n",
        "    y_merged = y_merged[indices]\n",
        "\n",
        "    print(f\"  Deep search: X={X_aug.shape}, y={y_aug.shape}\")\n",
        "    print(f\"  Merged:      X={X_merged.shape}, y={y_merged.shape}\")\n",
        "\n",
        "    # Save merged dataset\n",
        "    merged_path = os.path.join(DATASET_DIR, 'connect4_merged.npz')\n",
        "    np.savez_compressed(merged_path, X_train=X_merged, y_train=y_merged)\n",
        "    print(f\"\\n  Merged dataset saved -> {merged_path}\")\n",
        "    print(f\"  Size: {os.path.getsize(merged_path)/(1024**2):.1f} MB\")\n",
        "else:\n",
        "    if EXISTING_DATASET_PATH:\n",
        "        print(f\"Existing dataset not found at: {EXISTING_DATASET_PATH}\")\n",
        "    else:\n",
        "        print(\"No existing dataset path specified -- skipping merge.\")\n",
        "    print(\"To merge later, set EXISTING_DATASET_PATH and re-run this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Load in Your Training Notebook\n",
        "\n",
        "Copy the cell below into your training notebook to load the deep search dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Load the deep search dataset in your training notebook\n",
        "# Adjust the path to match your setup\n",
        "\n",
        "data = np.load(os.path.join(DATASET_DIR, 'connect4_deep_search.npz'))\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "\n",
        "print(f\"Loaded deep search dataset:\")\n",
        "print(f\"  X shape: {X_train.shape}\")   # (N, 6, 7, 2)\n",
        "print(f\"  y shape: {y_train.shape}\")   # (N,)\n",
        "print(f\"\\nReady for training!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
