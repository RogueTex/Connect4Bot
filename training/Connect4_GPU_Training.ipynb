{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adf72a4",
   "metadata": {},
   "source": [
    "# Connect4 GPU Training (Policy CNN)\n",
    "\n",
    "Train a CNN to predict the best move from 6x7x2 boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_DIR = '/content/drive/MyDrive/Connect4_Project'\n",
    "COMBINED_DIR = '/content/drive/MyDrive/Connect4_Combined'\n",
    "DATASET_DIR = f'{PROJECT_DIR}/datasets'\n",
    "MODEL_DIR = f'{COMBINED_DIR}/models'  # save CNN & Transformer to same folder\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print('Drive mounted')\n",
    "print('Dataset dir:', DATASET_DIR)\n",
    "print('Model dir:', MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78296f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/Import\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print('TF version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2733807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config â€” uses combined unique dataset from Connect4_Combined\n",
    "DATASET_PATH = '/content/drive/MyDrive/Connect4_Combined/datasets/connect4_combined_unique.npz'\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 40\n",
    "VAL_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "SEED = 42\n",
    "\n",
    "# Mixed precision for GPU speed\n",
    "USE_MIXED_PRECISION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed precision\n",
    "if USE_MIXED_PRECISION:\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print('Mixed precision enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (combined unique has pre-split train/val/test)\n",
    "npz = np.load(DATASET_PATH)\n",
    "if 'X_val' in npz:\n",
    "    X_train = npz['X_train']\n",
    "    y_train = npz['y_train']\n",
    "    X_val = npz['X_val']\n",
    "    y_val = npz['y_val']\n",
    "    X_test = npz['X_test']\n",
    "    y_test = npz['y_test']\n",
    "    print('Loaded pre-split: train/val/test')\n",
    "else:\n",
    "    X = npz['X_train']\n",
    "    y = npz['y_train']\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = None, None, None, None, None, None\n",
    "\n",
    "print('X_train:', X_train.shape if X_train is not None else X.shape)\n",
    "print('y_train:', y_train.shape if y_train is not None else y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd55c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split (only if not pre-split)\n",
    "if X_train is None:\n",
    "    np.random.seed(SEED)\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X, y = X[idx], y[idx]\n",
    "    n = len(X)\n",
    "    ntest, nval = int(n * TEST_SPLIT), int(n * VAL_SPLIT)\n",
    "    X_test, y_test = X[:ntest], y[:ntest]\n",
    "    X_val, y_val = X[ntest:ntest+nval], y[ntest:ntest+nval]\n",
    "    X_train, y_train = X[ntest+nval:], y[ntest+nval:]\n",
    "\n",
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Val:', X_val.shape, y_val.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c33884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data pipeline (one-hot labels for label smoothing)\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "def to_one_hot(x, y):\n",
    "    return x, tf.one_hot(tf.cast(y, tf.int32), NUM_CLASSES)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.shuffle(10000, seed=SEED).map(to_one_hot, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_ds = val_ds.map(to_one_hot, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_ds = test_ds.map(to_one_hot, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bc612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "inputs = keras.Input(shape=(6, 7, 2))\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
    "\n",
    "def residual_block(x, filters=64):\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "for _ in range(6):\n",
    "    x = residual_block(x, 64)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "outputs = layers.Dense(7, activation='softmax', dtype='float32')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name='accuracy'), keras.metrics.TopKCategoricalAccuracy(k=2, name='top2')]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "ckpt_path = f\"{MODEL_DIR}/connect4_cnn_best.keras\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_accuracy', save_best_only=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c120f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e205f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_metrics = model.evaluate(test_ds)\n",
    "print('Test metrics:', dict(zip(model.metrics_names, test_metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25621d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_path = f\"{MODEL_DIR}/connect4_cnn_final.keras\"\n",
    "model.save(final_path)\n",
    "print('Saved:', final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c93326",
   "metadata": {},
   "source": [
    "## Evaluation vs Weak MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0658c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Connect4 engine for evaluation\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Connect4Eval:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((6, 7), dtype=np.int8)\n",
    "        self.heights = np.zeros(7, dtype=np.int8)\n",
    "        self.current_player = 1\n",
    "        self.winner = None\n",
    "        self.move_count = 0\n",
    "\n",
    "    def copy(self):\n",
    "        g = Connect4Eval()\n",
    "        g.board = self.board.copy()\n",
    "        g.heights = self.heights.copy()\n",
    "        g.current_player = self.current_player\n",
    "        g.winner = self.winner\n",
    "        g.move_count = self.move_count\n",
    "        return g\n",
    "\n",
    "    def legal_moves(self):\n",
    "        return [c for c in range(7) if self.heights[c] < 6]\n",
    "\n",
    "    def make_move(self, col):\n",
    "        if self.heights[col] >= 6:\n",
    "            return False\n",
    "        row = self.heights[col]\n",
    "        self.board[row, col] = self.current_player\n",
    "        self.heights[col] += 1\n",
    "        self.move_count += 1\n",
    "        if self._check_win(row, col):\n",
    "            self.winner = self.current_player\n",
    "        elif self.move_count >= 42:\n",
    "            self.winner = 0\n",
    "        self.current_player *= -1\n",
    "        return True\n",
    "\n",
    "    def _check_win(self, row, col):\n",
    "        player = self.board[row, col]\n",
    "        # Vertical\n",
    "        if row <= 2 and np.sum(self.board[row:row+4, col]) == 4 * player:\n",
    "            return True\n",
    "        # Horizontal\n",
    "        for c in range(max(0, col-3), min(4, col+1)):\n",
    "            if np.sum(self.board[row, c:c+4]) == 4 * player:\n",
    "                return True\n",
    "        # Diagonals\n",
    "        for dr, dc in [(1, 1), (1, -1)]:\n",
    "            count = 1\n",
    "            for sign in [1, -1]:\n",
    "                r, c = row + sign*dr, col + sign*dc\n",
    "                while 0 <= r < 6 and 0 <= c < 7 and self.board[r, c] == player:\n",
    "                    count += 1\n",
    "                    r += sign*dr\n",
    "                    c += sign*dc\n",
    "            if count >= 4:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_terminal(self):\n",
    "        return self.winner is not None\n",
    "\n",
    "    def encode(self, perspective=1):\n",
    "        b = self.board if perspective == 1 else -self.board\n",
    "        enc = np.zeros((6, 7, 2), dtype=np.float32)\n",
    "        enc[:, :, 0] = (b == 1)\n",
    "        enc[:, :, 1] = (b == -1)\n",
    "        return enc\n",
    "\n",
    "def find_winning_move(game, player):\n",
    "    for col in game.legal_moves():\n",
    "        test = game.copy()\n",
    "        old_p = test.current_player\n",
    "        test.current_player = player\n",
    "        test.make_move(col)\n",
    "        if test.winner == player:\n",
    "            return col\n",
    "        test.current_player = old_p\n",
    "    return None\n",
    "\n",
    "def policy_move_with_rules(game, model, perspective=1):\n",
    "    win_col = find_winning_move(game, game.current_player)\n",
    "    if win_col is not None:\n",
    "        return win_col\n",
    "    block_col = find_winning_move(game, -game.current_player)\n",
    "    if block_col is not None:\n",
    "        return block_col\n",
    "    x = game.encode(perspective=perspective)[None, ...]\n",
    "    probs = model.predict(x, verbose=0)[0]\n",
    "    legal = game.legal_moves()\n",
    "    mask = np.full(7, -1e9, dtype=np.float32)\n",
    "    for c in legal:\n",
    "        mask[c] = 0.0\n",
    "    scores = probs + mask\n",
    "    return int(np.argmax(scores))\n",
    "\n",
    "class WeakMCTS:\n",
    "    def __init__(self, sims=100):\n",
    "        self.sims = sims\n",
    "\n",
    "    def get_move(self, game):\n",
    "        win = find_winning_move(game, game.current_player)\n",
    "        if win is not None:\n",
    "            return win\n",
    "        block = find_winning_move(game, -game.current_player)\n",
    "        if block is not None:\n",
    "            return block\n",
    "        return self._mcts(game, self.sims)\n",
    "\n",
    "    def _mcts(self, game, sims):\n",
    "        root_player = game.current_player\n",
    "        stats = {}\n",
    "        for _ in range(sims):\n",
    "            node = game.copy()\n",
    "            path = []\n",
    "            while not node.is_terminal():\n",
    "                state = hash(node.board.tobytes())\n",
    "                path.append(state)\n",
    "                if state not in stats:\n",
    "                    stats[state] = [0, 0.0]\n",
    "                moves = node.legal_moves()\n",
    "                if not moves:\n",
    "                    break\n",
    "                best_move = None\n",
    "                best_ucb = -1e9\n",
    "                parent_visits = stats[state][0]\n",
    "                for col in moves:\n",
    "                    test = node.copy()\n",
    "                    test.make_move(col)\n",
    "                    child = hash(test.board.tobytes())\n",
    "                    if child not in stats:\n",
    "                        stats[child] = [0, 0.0]\n",
    "                    visits, value = stats[child]\n",
    "                    if visits == 0:\n",
    "                        ucb = 1e9\n",
    "                    else:\n",
    "                        exploit = value / visits\n",
    "                        explore = 1.4 * np.sqrt(np.log(parent_visits + 1) / visits)\n",
    "                        ucb = exploit + explore\n",
    "                    if ucb > best_ucb:\n",
    "                        best_ucb = ucb\n",
    "                        best_move = col\n",
    "                node.make_move(best_move)\n",
    "                if stats[hash(node.board.tobytes())][0] == 0:\n",
    "                    path.append(hash(node.board.tobytes()))\n",
    "                    break\n",
    "            # rollout\n",
    "            depth = 0\n",
    "            while not node.is_terminal() and depth < 12:\n",
    "                moves = node.legal_moves()\n",
    "                if not moves:\n",
    "                    break\n",
    "                node.make_move(random.choice(moves))\n",
    "                depth += 1\n",
    "            result = 1.0 if node.winner == root_player else (-1.0 if node.winner == -root_player else 0.0)\n",
    "            for st in path:\n",
    "                if st in stats:\n",
    "                    stats[st][0] += 1\n",
    "                    stats[st][1] += result\n",
    "        # choose best\n",
    "        best_move, best_val = None, -1e9\n",
    "        for col in game.legal_moves():\n",
    "            test = game.copy()\n",
    "            test.make_move(col)\n",
    "            st = hash(test.board.tobytes())\n",
    "            if st in stats and stats[st][0] > 0:\n",
    "                val = stats[st][1] / stats[st][0]\n",
    "            else:\n",
    "                val = -1e9\n",
    "            if val > best_val:\n",
    "                best_val, best_move = val, col\n",
    "        return best_move if best_move is not None else random.choice(game.legal_moves())\n",
    "\n",
    "weak_mcts = WeakMCTS(sims=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate policy model vs weak MCTS (policy_move_with_rules: win/block + legal masking)\n",
    "EVAL_GAMES = 50\n",
    "\n",
    "def find_winning_move(game, player):\n",
    "    for col in game.legal_moves():\n",
    "        test = game.copy()\n",
    "        old_p = test.current_player\n",
    "        test.current_player = player\n",
    "        test.make_move(col)\n",
    "        if test.winner == player:\n",
    "            return col\n",
    "        test.current_player = old_p\n",
    "    return None\n",
    "\n",
    "def policy_move_with_rules(game, model, perspective=1):\n",
    "    win_col = find_winning_move(game, game.current_player)\n",
    "    if win_col is not None:\n",
    "        return win_col\n",
    "    block_col = find_winning_move(game, -game.current_player)\n",
    "    if block_col is not None:\n",
    "        return block_col\n",
    "    x = game.encode(perspective=perspective)[None, ...]\n",
    "    probs = model.predict(x, verbose=0)[0]\n",
    "    legal = game.legal_moves()\n",
    "    mask = np.full(7, -1e9, dtype=np.float32)\n",
    "    for c in legal:\n",
    "        mask[c] = 0.0\n",
    "    scores = probs + mask\n",
    "    return int(np.argmax(scores))\n",
    "\n",
    "wins = 0\n",
    "losses = 0\n",
    "ties = 0\n",
    "\n",
    "for _ in range(EVAL_GAMES):\n",
    "    game = Connect4Eval()\n",
    "    while not game.is_terminal():\n",
    "        if game.current_player == 1:\n",
    "            col = policy_move_with_rules(game, model, perspective=1)\n",
    "        else:\n",
    "            col = weak_mcts.get_move(game)\n",
    "        game.make_move(col)\n",
    "    if game.winner == 1:\n",
    "        wins += 1\n",
    "    elif game.winner == -1:\n",
    "        losses += 1\n",
    "    else:\n",
    "        ties += 1\n",
    "\n",
    "print(f\"Policy vs weak MCTS: W {wins}, L {losses}, T {ties} (games={EVAL_GAMES})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bb742",
   "metadata": {},
   "source": [
    "## Fine-Tune on High-Depth Dataset (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfea4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional high-depth dataset\n",
    "HIGH_DEPTH_DATASET_PATH = f'{DATASET_DIR}/connect4_high_depth.npz'\n",
    "FINE_TUNE_EPOCHS = 10\n",
    "FINE_TUNE_LR = 5e-4\n",
    "\n",
    "import os\n",
    "if os.path.exists(HIGH_DEPTH_DATASET_PATH):\n",
    "    npz2 = np.load(HIGH_DEPTH_DATASET_PATH)\n",
    "    X_hd = npz2['X_train']\n",
    "    y_hd = npz2['y_train']\n",
    "\n",
    "    idx = np.random.permutation(len(X_hd))\n",
    "    X_hd = X_hd[idx]\n",
    "    y_hd = y_hd[idx]\n",
    "\n",
    "    n = len(X_hd)\n",
    "    nval = int(n * 0.1)\n",
    "    X_hd_val, y_hd_val = X_hd[:nval], y_hd[:nval]\n",
    "    X_hd_train, y_hd_train = X_hd[nval:], y_hd[nval:]\n",
    "\n",
    "    hd_train_ds = tf.data.Dataset.from_tensor_slices((X_hd_train, y_hd_train))\n",
    "    hd_train_ds = hd_train_ds.shuffle(10000, seed=SEED).map(to_one_hot, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    hd_val_ds = tf.data.Dataset.from_tensor_slices((X_hd_val, y_hd_val))\n",
    "    hd_val_ds = hd_val_ds.map(to_one_hot, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(FINE_TUNE_LR),\n",
    "        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.05),\n",
    "        metrics=[keras.metrics.CategoricalAccuracy(name='accuracy'), keras.metrics.TopKCategoricalAccuracy(k=2, name='top2')]\n",
    "    )\n",
    "\n",
    "    model.fit(hd_train_ds, validation_data=hd_val_ds, epochs=FINE_TUNE_EPOCHS)\n",
    "else:\n",
    "    print('High-depth dataset not found, skipping fine-tune')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc97d1",
   "metadata": {},
   "source": [
    "## Self-Play Improvement Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELFPLAY_ITERATIONS = 3\n",
    "SELFPLAY_GAMES_PER_ITER = 300\n",
    "SELFPLAY_EPOCHS = 3\n",
    "SELFPLAY_EPSILON = 0.1\n",
    "\n",
    "\n",
    "def generate_selfplay_data(model, num_games):\n",
    "    X_sp = []\n",
    "    y_sp = []\n",
    "    for _ in range(num_games):\n",
    "        game = Connect4Eval()\n",
    "        while not game.is_terminal():\n",
    "            if random.random() < SELFPLAY_EPSILON:\n",
    "                col = random.choice(game.legal_moves())\n",
    "            else:\n",
    "                col = policy_move_with_rules(game, model, perspective=1 if game.current_player == 1 else -1)\n",
    "            # store from current player as +1 perspective\n",
    "            board = game.encode(perspective=game.current_player)\n",
    "            X_sp.append(board)\n",
    "            y_sp.append(col)\n",
    "            game.make_move(col)\n",
    "    return np.array(X_sp, dtype=np.float32), np.array(y_sp, dtype=np.int8)\n",
    "\n",
    "for it in range(SELFPLAY_ITERATIONS):\n",
    "    print(f\"Self-play iteration {it+1}/{SELFPLAY_ITERATIONS}\")\n",
    "    X_sp, y_sp = generate_selfplay_data(model, SELFPLAY_GAMES_PER_ITER)\n",
    "\n",
    "    sp_ds = tf.data.Dataset.from_tensor_slices((X_sp, y_sp))\n",
    "    sp_ds = sp_ds.shuffle(10000, seed=SEED).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    model.fit(sp_ds, epochs=SELFPLAY_EPOCHS)\n",
    "\n",
    "    # quick eval vs weak MCTS\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    ties = 0\n",
    "    for _ in range(20):\n",
    "        game = Connect4Eval()\n",
    "        while not game.is_terminal():\n",
    "            if game.current_player == 1:\n",
    "                col = policy_move_with_rules(game, model, perspective=1)\n",
    "            else:\n",
    "                col = weak_mcts.get_move(game)\n",
    "            game.make_move(col)\n",
    "        if game.winner == 1:\n",
    "            wins += 1\n",
    "        elif game.winner == -1:\n",
    "            losses += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "    print(f\"Eval vs weak MCTS: W {wins}, L {losses}, T {ties}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
