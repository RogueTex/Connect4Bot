{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b7c2ed",
   "metadata": {},
   "source": [
    "# Connect4 CNN2 Fine-Tuning Notebook\n",
    "\n",
    "This notebook fine-tunes a saved Connect4 CNN model using the loss-correction dataset generated from game logs.\n",
    "\n",
    "It supports both local VS Code and Google Colab + Drive paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc8d70",
   "metadata": {},
   "source": [
    "## 1) Environment Setup and Dependency Installation\n",
    "\n",
    "Install required packages (if needed), import libraries, and confirm runtime (GPU/CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c73eec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.19.0\n",
      "GPU available: True\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Optional for fresh Colab runtimes:\n",
    "# !pip -q install tensorflow==2.15.0 scikit-learn\n",
    "\n",
    "import tensorflow as tf\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('GPU available:', bool(tf.config.list_physical_devices('GPU')))\n",
    "print('Devices:', tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e047a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('TF:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a3dbe",
   "metadata": {},
   "source": [
    "## 2) Project Paths and Data/Model Mounting\n",
    "\n",
    "Define model/data/checkpoint paths. If using Colab, mount Google Drive and use absolute Drive paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fcdcc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_MODEL_PATH: /content/drive/MyDrive/Connect4_Combined/models/connect4_cnn_v2_best.keras\n",
      "FINETUNE_NPZ_PATH: /content/drive/MyDrive/Connect4_Combined/datasets/finetune_loss_cnn2_teacher_quick.npz\n",
      "BASE_DATASET_PATH: /content/drive/MyDrive/Connect4_Combined/datasets/connect4_combined_unique.npz\n",
      "OUT_MODEL_PATH: /content/drive/MyDrive/Connect4_Combined/models/connect4_cnn2_loss_finetuned.keras\n"
     ]
    }
   ],
   "source": [
    "# ====== CONFIG ======\n",
    "RUN_IN_COLAB = True\n",
    "\n",
    "# Drive model source (same family as your CNN training outputs)\n",
    "DRIVE_BASE = '/content/drive/MyDrive/Connect4_Combined'\n",
    "DRIVE_MODEL_DIR = f'{DRIVE_BASE}/models'\n",
    "DRIVE_DATASET_DIR = f'{DRIVE_BASE}/datasets'\n",
    "\n",
    "MODEL_CANDIDATES = [\n",
    "    f'{DRIVE_MODEL_DIR}/connect4_cnn_v2_best.keras',\n",
    "    f'{DRIVE_MODEL_DIR}/connect4_cnn_v2_final.keras',\n",
    "    f'{DRIVE_MODEL_DIR}/connect4_cnn_final.keras',\n",
    "]\n",
    "\n",
    "NPZ_CANDIDATES = [\n",
    "    f'{DRIVE_DATASET_DIR}/finetune_loss_cnn2_teacher_quick.npz',\n",
    "    f'{DRIVE_DATASET_DIR}/finetune_loss_cnn2_teacher.npz',\n",
    "    '/content/finetune_loss_cnn2_teacher_quick.npz',\n",
    "    '/content/finetune_loss_cnn2_teacher.npz',\n",
    "]\n",
    "\n",
    "BASE_DATASET_PATH = f'{DRIVE_DATASET_DIR}/connect4_combined_unique.npz'\n",
    "MIX_WITH_BASE_DATASET = True\n",
    "BASE_MIX_RATIO = 1.0\n",
    "BASE_SAMPLE_WEIGHT = 0.85\n",
    "\n",
    "BASE_MODEL_PATH = next((p for p in MODEL_CANDIDATES if os.path.exists(p)), MODEL_CANDIDATES[0])\n",
    "FINETUNE_NPZ_PATH = next((p for p in NPZ_CANDIDATES if os.path.exists(p)), NPZ_CANDIDATES[0])\n",
    "OUT_MODEL_PATH = f'{DRIVE_MODEL_DIR}/connect4_cnn2_loss_finetuned.keras'\n",
    "\n",
    "SEED = 42\n",
    "VAL_SIZE = 0.15\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 28\n",
    "LEARNING_RATE = 2e-5\n",
    "EARLY_STOP_PATIENCE = 4\n",
    "FREEZE_PREFIX_FRACTION = 0.0\n",
    "\n",
    "print('BASE_MODEL_PATH:', BASE_MODEL_PATH)\n",
    "print('FINETUNE_NPZ_PATH:', FINETUNE_NPZ_PATH)\n",
    "print('BASE_DATASET_PATH:', BASE_DATASET_PATH)\n",
    "print('OUT_MODEL_PATH:', OUT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "013f4699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Resolved model: /content/drive/MyDrive/Connect4_Combined/models/connect4_cnn_v2_best.keras\n",
      "Resolved npz  : /content/drive/MyDrive/Connect4_Combined/datasets/finetune_loss_cnn2_teacher_quick.npz\n"
     ]
    }
   ],
   "source": [
    "if RUN_IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Re-resolve after Drive mount so detection is accurate\n",
    "BASE_MODEL_PATH = next((p for p in MODEL_CANDIDATES if os.path.exists(p)), None)\n",
    "FINETUNE_NPZ_PATH = next((p for p in NPZ_CANDIDATES if os.path.exists(p)), None)\n",
    "\n",
    "print('Resolved model:', BASE_MODEL_PATH)\n",
    "print('Resolved npz  :', FINETUNE_NPZ_PATH)\n",
    "\n",
    "if BASE_MODEL_PATH is None:\n",
    "    print('Checked model candidates:', MODEL_CANDIDATES)\n",
    "    raise AssertionError('Model not found on Drive. Please verify Connect4_Combined/models contains a saved .keras model.')\n",
    "\n",
    "if FINETUNE_NPZ_PATH is None:\n",
    "    print('Checked NPZ candidates:', NPZ_CANDIDATES)\n",
    "    raise AssertionError('Finetune NPZ not found. Expected under Connect4_Combined/datasets/finetune_loss_cnn2_teacher_quick.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a41a3a",
   "metadata": {},
   "source": [
    "## 3) Dataset Loading and Split Verification\n",
    "\n",
    "Load NPZ tensors, print sample counts/shapes, and verify label distribution before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6debab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune: (91, 6, 7, 2) (91,)\n",
      "Finetune move dist: [14, 20, 22, 9, 17, 6, 3]\n",
      "label_source: {'teacher_mcts': 91}\n",
      "changed_labels: 66\n",
      "Base mixed: 91 samples from /content/drive/MyDrive/Connect4_Combined/datasets/connect4_combined_unique.npz\n",
      "Final: (182, 6, 7, 2) (182,) (182,)\n",
      "Final weight range: 0.8500000238418579 1.899999976158142\n",
      "Final move dist: [29, 31, 35, 21, 32, 19, 15]\n"
     ]
    }
   ],
   "source": [
    "ft = np.load(FINETUNE_NPZ_PATH, allow_pickle=True)\n",
    "X_ft = ft['X_train'].astype(np.float32)\n",
    "y_ft = ft['y_train'].astype(np.int64)\n",
    "w_ft = ft['sample_weight'].astype(np.float32)\n",
    "\n",
    "print('Finetune:', X_ft.shape, y_ft.shape)\n",
    "print('Finetune move dist:', np.bincount(y_ft, minlength=7).tolist())\n",
    "if 'label_source' in ft.files:\n",
    "    u, c = np.unique(ft['label_source'], return_counts=True)\n",
    "    print('label_source:', dict(zip(u.tolist(), c.tolist())))\n",
    "if 'original_chosen_col' in ft.files:\n",
    "    print('changed_labels:', int(np.sum(y_ft != ft['original_chosen_col'])))\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "if MIX_WITH_BASE_DATASET and os.path.exists(BASE_DATASET_PATH):\n",
    "    base = np.load(BASE_DATASET_PATH, allow_pickle=True)\n",
    "    X_base = base['X_train'].astype(np.float32)\n",
    "    y_base = base['y_train'].astype(np.int64)\n",
    "\n",
    "    n_pick = min(int(len(X_ft) * BASE_MIX_RATIO), len(X_base))\n",
    "    idx = rng.choice(len(X_base), size=n_pick, replace=False)\n",
    "    Xb = X_base[idx]\n",
    "    yb = y_base[idx]\n",
    "    wb = np.full((n_pick,), BASE_SAMPLE_WEIGHT, dtype=np.float32)\n",
    "\n",
    "    X = np.concatenate([X_ft, Xb], axis=0)\n",
    "    y = np.concatenate([y_ft, yb], axis=0)\n",
    "    w = np.concatenate([w_ft, wb], axis=0)\n",
    "\n",
    "    perm = rng.permutation(len(y))\n",
    "    X, y, w = X[perm], y[perm], w[perm]\n",
    "\n",
    "    print(f'Base mixed: {n_pick} samples from {BASE_DATASET_PATH}')\n",
    "else:\n",
    "    X, y, w = X_ft, y_ft, w_ft\n",
    "    print('Base mixing skipped.')\n",
    "\n",
    "print('Final:', X.shape, y.shape, w.shape)\n",
    "print('Final weight range:', float(w.min()), float(w.max()))\n",
    "print('Final move dist:', np.bincount(y, minlength=7).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ea4d8",
   "metadata": {},
   "source": [
    "## 4) Model Loading (Saved CNN Checkpoint)\n",
    "\n",
    "Load the saved `.keras` model and run a forward pass sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6d343ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (154, 6, 7, 2) (154,)\n",
      "Val: (28, 6, 7, 2) (28,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 182 variables whereas the saved optimizer has 186 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_layer']\n",
      "Received: inputs=Tensor(shape=(4, 6, 7, 2))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and forward pass succeeded.\n",
      "Classifier head already matches 7 outputs.\n",
      "Epoch 1/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15s/step - accuracy: 0.4263 - loss: 2.7188 - top2_acc: 0.6456 - val_accuracy: 0.2857 - val_loss: 3.9245 - val_top2_acc: 0.6071 - learning_rate: 2.0000e-05\n",
      "Epoch 2/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.4402 - loss: 2.6143 - top2_acc: 0.6638 - val_accuracy: 0.2857 - val_loss: 3.9072 - val_top2_acc: 0.6071 - learning_rate: 2.0000e-05\n",
      "Epoch 3/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4541 - loss: 2.5802 - top2_acc: 0.6586 - val_accuracy: 0.2857 - val_loss: 3.8908 - val_top2_acc: 0.6071 - learning_rate: 2.0000e-05\n",
      "Epoch 4/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.4610 - loss: 2.5496 - top2_acc: 0.6335 - val_accuracy: 0.2857 - val_loss: 3.8762 - val_top2_acc: 0.6071 - learning_rate: 2.0000e-05\n",
      "Epoch 5/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4792 - loss: 2.4654 - top2_acc: 0.6751 - val_accuracy: 0.2857 - val_loss: 3.8635 - val_top2_acc: 0.6071 - learning_rate: 2.0000e-05\n",
      "Epoch 6/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4558 - loss: 2.4732 - top2_acc: 0.6742 - val_accuracy: 0.2857 - val_loss: 3.8480 - val_top2_acc: 0.6071 - learning_rate: 2.0000e-05\n",
      "Epoch 7/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4766 - loss: 2.3715 - top2_acc: 0.6950 - val_accuracy: 0.2857 - val_loss: 3.8325 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 8/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.4835 - loss: 2.2917 - top2_acc: 0.6742 - val_accuracy: 0.2857 - val_loss: 3.8160 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 9/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4835 - loss: 2.3302 - top2_acc: 0.6672 - val_accuracy: 0.2857 - val_loss: 3.7979 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 10/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4766 - loss: 2.2221 - top2_acc: 0.7062 - val_accuracy: 0.2857 - val_loss: 3.7822 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 11/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4991 - loss: 2.2124 - top2_acc: 0.7036 - val_accuracy: 0.2857 - val_loss: 3.7664 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 12/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4991 - loss: 2.2638 - top2_acc: 0.7106 - val_accuracy: 0.2857 - val_loss: 3.7521 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 13/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5104 - loss: 2.1844 - top2_acc: 0.6950 - val_accuracy: 0.2857 - val_loss: 3.7375 - val_top2_acc: 0.5357 - learning_rate: 2.0000e-05\n",
      "Epoch 14/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5242 - loss: 2.1736 - top2_acc: 0.7314 - val_accuracy: 0.2857 - val_loss: 3.7198 - val_top2_acc: 0.5357 - learning_rate: 2.0000e-05\n",
      "Epoch 15/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5104 - loss: 2.1466 - top2_acc: 0.7010 - val_accuracy: 0.2857 - val_loss: 3.7017 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 16/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5008 - loss: 2.1342 - top2_acc: 0.7218 - val_accuracy: 0.3214 - val_loss: 3.6852 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 17/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5286 - loss: 2.0835 - top2_acc: 0.7218 - val_accuracy: 0.3214 - val_loss: 3.6704 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 18/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5216 - loss: 2.1269 - top2_acc: 0.7080 - val_accuracy: 0.3214 - val_loss: 3.6580 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 19/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5468 - loss: 2.0637 - top2_acc: 0.7496 - val_accuracy: 0.3214 - val_loss: 3.6453 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 20/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5121 - loss: 2.0352 - top2_acc: 0.7496 - val_accuracy: 0.3214 - val_loss: 3.6328 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 21/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5606 - loss: 1.9799 - top2_acc: 0.7270 - val_accuracy: 0.3214 - val_loss: 3.6189 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 22/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999ms/step - accuracy: 0.5468 - loss: 1.8857 - top2_acc: 0.7383 - val_accuracy: 0.3214 - val_loss: 3.6085 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 23/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.5537 - loss: 1.9872 - top2_acc: 0.7652 - val_accuracy: 0.3214 - val_loss: 3.5965 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 24/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5606 - loss: 1.9637 - top2_acc: 0.7470 - val_accuracy: 0.2857 - val_loss: 3.5836 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 25/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5676 - loss: 1.9114 - top2_acc: 0.7565 - val_accuracy: 0.2857 - val_loss: 3.5705 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 26/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5676 - loss: 1.8815 - top2_acc: 0.7704 - val_accuracy: 0.2857 - val_loss: 3.5590 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 27/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6092 - loss: 1.8601 - top2_acc: 0.7747 - val_accuracy: 0.2857 - val_loss: 3.5464 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Epoch 28/28\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.5953 - loss: 1.8467 - top2_acc: 0.7660 - val_accuracy: 0.2857 - val_loss: 3.5329 - val_top2_acc: 0.5714 - learning_rate: 2.0000e-05\n",
      "Saved best model: /content/drive/MyDrive/Connect4_Combined/models/connect4_cnn2_loss_finetuned.keras\n"
     ]
    }
   ],
   "source": [
    "# Split first so we can validate shape assumptions early\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n",
    "    X, y, w, test_size=VAL_SIZE, random_state=SEED, stratify=y\n",
    ")\n",
    "y_train_oh = keras.utils.to_categorical(y_train, num_classes=7).astype(np.float32)\n",
    "y_val_oh = keras.utils.to_categorical(y_val, num_classes=7).astype(np.float32)\n",
    "\n",
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Val:', X_val.shape, y_val.shape)\n",
    "\n",
    "# ---- Section 4: model loading + forward pass sanity ----\n",
    "model = keras.models.load_model(BASE_MODEL_PATH)\n",
    "_ = model(X_train[:4], training=False)\n",
    "print('Loaded model and forward pass succeeded.')\n",
    "\n",
    "# ---- Section 5: classifier head update for new classes ----\n",
    "num_classes = 7\n",
    "if int(model.output_shape[-1]) != num_classes:\n",
    "    x = model.layers[-2].output\n",
    "    new_out = keras.layers.Dense(num_classes, activation='softmax', name='policy_head_ft')(x)\n",
    "    model = keras.Model(inputs=model.input, outputs=new_out)\n",
    "    print('Replaced classifier head to 7 outputs.')\n",
    "else:\n",
    "    print('Classifier head already matches 7 outputs.')\n",
    "\n",
    "# ---- Section 6: fine-tuning configuration (freeze/unfreeze) ----\n",
    "if FREEZE_PREFIX_FRACTION > 0:\n",
    "    freeze_upto = int(len(model.layers) * FREEZE_PREFIX_FRACTION)\n",
    "    for layer in model.layers[:freeze_upto]:\n",
    "        layer.trainable = False\n",
    "    print(f'Froze first {freeze_upto} layers out of {len(model.layers)}')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top2_acc')]\n",
    ")\n",
    "\n",
    "# ---- Section 7 + 8: training, validation metrics, checkpointing ----\n",
    "os.makedirs(os.path.dirname(OUT_MODEL_PATH), exist_ok=True)\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLY_STOP_PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=OUT_MODEL_PATH, monitor='val_loss', save_best_only=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_oh,\n",
    "    validation_data=(X_val, y_val_oh, w_val),\n",
    "    sample_weight=w_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print('Saved best model:', OUT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f010dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'loss': 3.532895565032959, 'compile_metrics': 0.2857142984867096}\n",
      "History: /content/drive/MyDrive/Connect4_Combined/models/connect4_cnn2_loss_finetuned_history.json\n",
      "sample 0: pred=3 conf=0.415 label=3\n",
      "sample 1: pred=4 conf=0.463 label=4\n",
      "sample 2: pred=2 conf=0.916 label=0\n",
      "sample 3: pred=1 conf=0.946 label=1\n",
      "sample 4: pred=4 conf=0.541 label=4\n",
      "sample 5: pred=0 conf=0.696 label=2\n",
      "sample 6: pred=2 conf=0.304 label=1\n",
      "sample 7: pred=4 conf=0.506 label=3\n"
     ]
    }
   ],
   "source": [
    "# ---- Section 9: inference sanity check on sample boards ----\n",
    "best_model = keras.models.load_model(OUT_MODEL_PATH)\n",
    "eval_out = best_model.evaluate(X_val, y_val_oh, sample_weight=w_val, verbose=0)\n",
    "print('Validation metrics:', dict(zip(best_model.metrics_names, [float(v) for v in eval_out])))\n",
    "\n",
    "hist_path = OUT_MODEL_PATH.replace('.keras', '_history.json')\n",
    "with open(hist_path, 'w') as f:\n",
    "    json.dump({k: [float(vv) for vv in vals] for k, vals in history.history.items()}, f, indent=2)\n",
    "print('History:', hist_path)\n",
    "\n",
    "# Show a few predictions vs labels\n",
    "sample_n = min(8, len(X_val))\n",
    "pred = best_model.predict(X_val[:sample_n], verbose=0)\n",
    "pred_col = pred.argmax(axis=1)\n",
    "conf = pred.max(axis=1)\n",
    "\n",
    "for i in range(sample_n):\n",
    "    print(f'sample {i}: pred={int(pred_col[i])} conf={float(conf[i]):.3f} label={int(y_val[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f44df3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 86 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7dcf02be7f60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base val metrics : {'loss': 4.010879039764404, 'compile_metrics': 0.3571428656578064}\n",
      "FT val metrics   : {'loss': 3.532895565032959, 'compile_metrics': 0.2857142984867096}\n",
      "Base on loss-set : {'loss': 4.924814701080322, 'compile_metrics': 0.2637362778186798}\n",
      "FT on loss-set   : {'loss': 3.9568326473236084, 'compile_metrics': 0.34065935015678406}\n"
     ]
    }
   ],
   "source": [
    "# Compare base model vs finetuned model on same splits\n",
    "base_model = keras.models.load_model(BASE_MODEL_PATH)\n",
    "ft_model = keras.models.load_model(OUT_MODEL_PATH)\n",
    "\n",
    "base_eval = base_model.evaluate(X_val, y_val_oh, sample_weight=w_val, verbose=0)\n",
    "ft_eval = ft_model.evaluate(X_val, y_val_oh, sample_weight=w_val, verbose=0)\n",
    "\n",
    "print('Base val metrics :', dict(zip(base_model.metrics_names, [float(v) for v in base_eval])))\n",
    "print('FT val metrics   :', dict(zip(ft_model.metrics_names, [float(v) for v in ft_eval])))\n",
    "\n",
    "# Loss-focused teacher set comparison (hard set)\n",
    "X_ft_eval = X_ft.astype(np.float32)\n",
    "y_ft_oh = keras.utils.to_categorical(y_ft, num_classes=7).astype(np.float32)\n",
    "\n",
    "base_ft_eval = base_model.evaluate(X_ft_eval, y_ft_oh, sample_weight=w_ft, verbose=0)\n",
    "ft_ft_eval = ft_model.evaluate(X_ft_eval, y_ft_oh, sample_weight=w_ft, verbose=0)\n",
    "\n",
    "print('Base on loss-set :', dict(zip(base_model.metrics_names, [float(v) for v in base_ft_eval])))\n",
    "print('FT on loss-set   :', dict(zip(ft_model.metrics_names, [float(v) for v in ft_ft_eval])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a9f5f",
   "metadata": {},
   "source": [
    "## 10) Go / No-Go Gates (Regression + Hard-Loss + Professor Dataset)\n",
    "\n",
    "This section runs deployment gates:\n",
    "- No harmful regression on mixed validation\n",
    "- Improvement on hard loss-teacher set\n",
    "- Optional comparison on professor `mcts7500_pool.pickle` dataset (if file exists)\n",
    "- Final GO / NO-GO verdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74460210",
   "metadata": {},
   "source": [
    "## 5) Classifier Head Update for New Classes\n",
    "\n",
    "The training cell below checks output width and replaces the final head only if it does not match 7 Connect4 action classes.\n",
    "\n",
    "## 6) Fine-Tuning Configuration (Freeze/Unfreeze Layers)\n",
    "\n",
    "Use `FREEZE_PREFIX_FRACTION` to freeze early layers for safer adaptation.\n",
    "\n",
    "## 7) Training Loop and Validation Metrics\n",
    "\n",
    "Tracks training loss, validation loss, accuracy, and top-2 accuracy.\n",
    "\n",
    "## 8) Checkpointing and Best-Model Saving\n",
    "\n",
    "Saves best checkpoint by validation loss and exports training history JSON.\n",
    "\n",
    "## 9) Inference Sanity Check on Sample Inputs\n",
    "\n",
    "Runs predictions on validation samples and prints predicted move vs label + confidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
