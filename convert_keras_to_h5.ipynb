{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert Connect4 Models from .keras to .h5\n",
        "\n",
        "Run this in Google Colab. Connect your Drive, set the model folder path below, then run all cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models to convert from Drive\n",
        "# CNN v2:      connect4_cnn_v2_final.keras\n",
        "# Transformer: connect4_transformer_final.keras\n",
        "MODEL_FOLDER = \"/content/drive/MyDrive/Connect4_Combined/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files in /content/drive/MyDrive/Connect4_Combined/models:\n",
            "  - connect4_cnn_best.keras\n",
            "  - connect4_transformer_best.keras\n",
            "  - connect4_transformer_final.keras\n",
            "  - cnn_vs_transformer.png\n",
            "  - connect4_cnn_v2_best.keras\n",
            "  - connect4_cnn_v2_final.keras\n",
            "  - connect4_cnn2_loss_finetuned_history.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List files in the folder to confirm path\n",
        "if os.path.exists(MODEL_FOLDER):\n",
        "    print(f\"Files in {MODEL_FOLDER}:\")\n",
        "    for f in os.listdir(MODEL_FOLDER):\n",
        "        print(f\"  - {f}\")\n",
        "else:\n",
        "    print(f\"Folder not found: {MODEL_FOLDER}\")\n",
        "    print(\"Edit MODEL_FOLDER in the cell above.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m797.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q \"tensorflow>=2.16\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Custom layers from Connect4_CNN_Transformer_Training.ipynb (required to load Transformer)\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class BoardPatchEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.proj = layers.Dense(self.embed_dim)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.reshape(x, [-1, 42, 2])\n",
        "        return self.proj(x)\n",
        "\n",
        "class SinusoidalPositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, seq_len, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        pe = np.zeros((1, self.seq_len, self.embed_dim), dtype=np.float32)\n",
        "        for pos in range(self.seq_len):\n",
        "            for i in range(0, self.embed_dim, 2):\n",
        "                pe[0, pos, i] = np.sin(pos / 10000**(i / self.embed_dim))\n",
        "                if i + 1 < self.embed_dim:\n",
        "                    pe[0, pos, i+1] = np.cos(pos / 10000**(i / self.embed_dim))\n",
        "        self.pos_emb = self.add_weight(name='pos_emb', shape=(1, self.seq_len, self.embed_dim),\n",
        "                                       initializer=keras.initializers.Constant(pe), trainable=False)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_emb\n",
        "\n",
        "CUSTOM_OBJECTS = {\n",
        "    'BoardPatchEmbedding': BoardPatchEmbedding,\n",
        "    'SinusoidalPositionalEmbedding': SinusoidalPositionalEmbedding,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting connect4_cnn_v2_final.keras -> connect4_cnn_v2_final.h5 ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Done: /content/drive/MyDrive/Connect4_Combined/models/connect4_cnn_v2_final.h5 (136.7 MB)\n",
            "Converting connect4_transformer_final.keras -> connect4_transformer_final.h5 ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Done: /content/drive/MyDrive/Connect4_Combined/models/connect4_transformer_final.h5 (49.5 MB)\n",
            "\n",
            "All done. Download the .h5 files from Drive or copy to your project.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "for name in [\"connect4_cnn_v2_final\", \"connect4_transformer_final\"]:\n",
        "    keras_path = os.path.join(MODEL_FOLDER, f\"{name}.keras\")\n",
        "    h5_path = os.path.join(MODEL_FOLDER, f\"{name}.h5\")\n",
        "    \n",
        "    if not os.path.exists(keras_path):\n",
        "        print(f\"Skipping {name}: {keras_path} not found\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"Converting {name}.keras -> {name}.h5 ...\")\n",
        "    custom = CUSTOM_OBJECTS if \"transformer\" in name else {}\n",
        "    model = tf.keras.models.load_model(keras_path, custom_objects=custom)\n",
        "    model.save(h5_path)\n",
        "    size_mb = os.path.getsize(h5_path) / (1024 * 1024)\n",
        "    print(f\"  Done: {h5_path} ({size_mb:.1f} MB)\")\n",
        "\n",
        "print(\"\\nAll done. Download the .h5 files from Drive or copy to your project.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
